{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "determined-defeat",
   "metadata": {},
   "source": [
    "## Семинар 3. Нейронные сети: градиентные методы оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-helen",
   "metadata": {},
   "source": [
    "**Библиотеки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liked-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-experience",
   "metadata": {},
   "source": [
    "**1. Автоматическое дифференцирование**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-buying",
   "metadata": {},
   "source": [
    "Back Propagation - частный случай автоматического дифференцирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-department",
   "metadata": {},
   "source": [
    "**Пример**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-cooking",
   "metadata": {},
   "source": [
    "Рассмотрим функцию\n",
    "<center>$\n",
    "\\begin{equation*}\n",
    "    f(\\mathbf{x})=\n",
    "        x_3\\cdot\n",
    "        \\cos\\left(\n",
    "            \\dfrac{x_1}{x_2}\n",
    "        \\right)\\cdot\n",
    "        \\left(\n",
    "            \\exp(x_3)+\\dfrac{x_1}{x_2}\n",
    "        \\right)\n",
    "\\end{equation*}\n",
    "$</center>\n",
    "\n",
    "Пусть необходимо найти градиент данной функции.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-league",
   "metadata": {},
   "source": [
    "Представим граф вычилений данной функции:\n",
    "![Граф вычислений](img/calc_graph.png \"Граф вычислений\")\n",
    "\n",
    "Рассмотрим производную $\\partial f/\\partial x_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-waters",
   "metadata": {},
   "source": [
    "**Дифференцирование вперед**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-crowd",
   "metadata": {},
   "source": [
    "* $\\dfrac{\\partial z_1}{\\partial x_1}=\\dfrac{1}{x_2}$\n",
    "* $\\dfrac{\\partial z_2}{\\partial x_1}=0$\n",
    "* $\\dfrac{\\partial z_3}{\\partial x_1}=\\dfrac{\\partial z_3}{\\partial z_1}\\cdot\\dfrac{\\partial z_1}{\\partial x_1}=-\\sin\\left(\\dfrac{x1}{x2}\\right)\\dfrac{1}{x_2}$\n",
    "* $\\dfrac{\\partial z_4}{\\partial x_1}=\\dfrac{\\partial z_4}{\\partial z_1}\\cdot\\dfrac{\\partial z_1}{\\partial x_1}+\\dfrac{\\partial z_4}{\\partial z_2}\\cdot\\dfrac{\\partial z_2}{\\partial x_1}=\\dfrac{1}{x_2}$\n",
    "* $\\dfrac{\\partial z_5}{\\partial x_1}=\\dfrac{\\partial z_5}{\\partial z_3}\\cdot\\dfrac{\\partial z_3}{\\partial x_1}+\\dfrac{\\partial z_5}{\\partial z_4}\\dfrac{\\partial z_4}{\\partial x_1}=-\\sin\\left(\\dfrac{x_1}{x_2}\\right)\\dfrac{1}{x_2}\\left(\\exp(x_3)+\\dfrac{x_1}{x_2}\\right)+\\cos\\left(\\dfrac{x_1}{x_2}\\right)\\dfrac{1}{x_2}$\n",
    "* $\\dfrac{\\partial z_6}{\\partial x_1}=\\dfrac{\\partial z_6}{\\partial z_5}\\cdot\\dfrac{\\partial z_5}{\\partial x_1}+\\dfrac{\\partial z_6}{\\partial x_3}\\cdot\\dfrac{\\partial x_3}{\\partial x_1}=x_3\\left(-\\sin\\left(\\dfrac{x_1}{x_2}\\right)\\dfrac{1}{x_2}\\left(\\exp(x_3)+\\dfrac{x_1}{x_2}\\right)+\\cos\\left(\\dfrac{x_1}{x_2}\\right)\\dfrac{1}{x_2}\\right)$\n",
    "* $\\dfrac{\\partial f}{\\partial x_1}=\\dfrac{\\partial f}{\\partial x_1}\\cdot\\dfrac{\\partial z_6}{\\partial x_1}=x_3\\left(-\\sin\\left(\\dfrac{x_1}{x_2}\\right)\\dfrac{1}{x_2}\\left(\\exp(x_3)+\\dfrac{x_1}{x_2}\\right)+\\cos\\left(\\dfrac{x_1}{x_2}\\right)\\dfrac{1}{x_2}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-chapel",
   "metadata": {},
   "source": [
    "**Дифференцирование назад**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-steering",
   "metadata": {},
   "source": [
    "![Дифференцирование назад](img/diff_back.png 'Дифференцирование назад')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-disney",
   "metadata": {},
   "source": [
    "Дифференцирование назад применяется при вычислении градиента сложных функций. А нейросеть и есть сложная функция. Применение дифференцирования назад при обучении сети называется Back Propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-bhutan",
   "metadata": {},
   "source": [
    "**Плюсы и минусы методов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-douglas",
   "metadata": {},
   "source": [
    "Дифференцирование веред:\n",
    "* использует меньше памяти, чем дифференцирование назад;\n",
    "* вычислительная сложность зависит от числа параметров.\n",
    "\n",
    "Дифференцирование назад:\n",
    "* использует больше памяти, чем дифференцирование вперед;\n",
    "* вычислительная сложность не зависит от числа параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-circle",
   "metadata": {},
   "source": [
    "**2. MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impaired-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e4668860f34e72a7ba9a3134999a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72b344fb73442f9ac073e053ad61139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8843345f1c314632b11f79a27c910460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9e04496fa343d1818b15d2f55b53b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ski6a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "MNIST_train = datasets.MNIST('./mnist', train=True, download=True,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "MNIST_test = datasets.MNIST('./mnist', train=False, download=True,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "# Изначально датасет представлен в виде изображений PIL image.\n",
    "# Для того, чтобы получить данные в удобном для torch виде, применяется\n",
    "# трансформация transform=transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-mortgage",
   "metadata": {},
   "source": [
    "**Выборка**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loving-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1368x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, gs = plt.figure(figsize=(19,4)), gridspec.GridSpec(1, 4)\n",
    "\n",
    "ax = []\n",
    "\n",
    "for i in range(4):\n",
    "    ax.append(fig.add_subplot(gs[i]))\n",
    "    ax[i].imshow(np.array(MNIST_train[i][0][0]), 'gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-marshall",
   "metadata": {},
   "source": [
    "Нейросеть принимает на вход вектор, таким образом небходимо \"растянуть\" матрицу в вектор - первая строка - первые 28 элементов вектора, вторая строка - вторые 28 элеметнов и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-structure",
   "metadata": {},
   "source": [
    "**Полносвязная нейронная сеть (Персептрон)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-theater",
   "metadata": {},
   "source": [
    "![Персептрон](img/perseptron.png 'Персептрон')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-warehouse",
   "metadata": {},
   "source": [
    "Пусть количество нейронов в каждом скрытом слое одинаковое. Пусть функции активации везде одинаковые."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-tradition",
   "metadata": {},
   "source": [
    "Перепишем в матричном виде:\n",
    "<center>$\n",
    "\\begin{equation*}\n",
    "    f(\\mathbf{w}, W)=\n",
    "    W_{n_2+1}\\sigma\\left(\n",
    "        \\cdots W_2\\sigma\\left(\n",
    "            W_1\\mathbf{x}\n",
    "        \\right)\\cdots\n",
    "    \\right)\n",
    "\\end{equation*}\n",
    "$,</center>\n",
    "\n",
    "где\n",
    "* $n$ - размерность пространства признаков (`input_dim`);\n",
    "* $n_1$ - размерность скрытого слоя (`hidden_dim`);\n",
    "* $n_2$ - количество скрытых слоев (`num_layers`);\n",
    "* $n_3$ - размерность пространтсва ответов (`output_dim`).\n",
    "\n",
    "Заметим, что при $n_2=0$ получается линейная модель, то есть линейная модель это частный случай полносвязного персептрона."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-investigator",
   "metadata": {},
   "source": [
    "**Задание нейронной сети в PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hispanic-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim=784, num_layers=0,\n",
    "                 hidden_dim=64, output_dim=10, p=0.0, device='cpu'):\n",
    "        # device - устройство, на котором будут производиться вычисления\n",
    "        \n",
    "        super(Perceptron, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential()\n",
    "        \n",
    "        prev_size = input_dim\n",
    "        for i in range(num_layers):\n",
    "            # Линейный модуль - добавление одного слоя полносвязной\n",
    "            # нейронной сети - реадизация скалярного произведения Wx\n",
    "            self.layers.add_module('layer{}'.format(i+1),\n",
    "                                   torch.nn.Linear(prev_size, hidden_dim))\n",
    "            # torch.nn.Linear(prev_size, hidden_dim),\n",
    "            # prev_size - кол-во нейронов на предыдущем слое (на входе)\n",
    "            # hidden_dim - кол-во нейронов на следующем слое (на выходе)\n",
    "            \n",
    "            # Нелинейный модуль - сигма-функция (в нашем случае ReLU)\n",
    "            self.layers.add_module('relu{}'.format(i+1), torch.nn.ReLU())\n",
    "            \n",
    "            # Удаление нейрона с вероятностью p (Реализация Drop Out):\n",
    "            self.layers.add_module('dropout{}'.format(i+1), torch.nn.Dropout(p=p))\n",
    "            \n",
    "            # Отслеживание согласовонности размерностей выходов и входов\n",
    "            # смежных слоев:\n",
    "            prev_size = hidden_dim\n",
    "            \n",
    "        # Последний линейный слой\n",
    "        self.layers.add_module('classifier',\n",
    "                                torch.nn.Linear(prev_size, output_dim))\n",
    "        self.to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "polyphonic-forward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если есть GPU, то подсчеты будт производиться на GPU, в ином слуаче\n",
    "# расчеты будут производиться на CPU.\n",
    "\n",
    "# Использование GPU для нейронных сетей является наиболее предпочтительным\n",
    "# ввиду того, что матричные вычисления на видеокарте работают намного быстрее,\n",
    "# нежели на процессоре.\n",
    "\n",
    "# У меня почему-то GPU не доступна.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-outreach",
   "metadata": {},
   "source": [
    "Что из себя представляет модель Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "czech-indonesia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(\n",
       "  (layers): Sequential(\n",
       "    (classifier): Linear(in_features=784, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perceptron(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-british",
   "metadata": {},
   "source": [
    "В слоях содержится только один линейный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "casual-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(\n",
       "  (layers): Sequential(\n",
       "    (layer1): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perceptron(num_layers=1, device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-activity",
   "metadata": {},
   "source": [
    "Слой 1: Линейный слой $\\to$ ReLU $\\to$ DropOut с вер-стью 0 $\\to$ Линейный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-shark",
   "metadata": {},
   "source": [
    "В линейных слоях есть параметр `bias=True`. Данный параметр отвечает за добавление единицы к признакам объекта. То есть если `bias=True`, то сами признаки подаются на вход сети без преобразования (без добалвения к ним $1$), PyTorch будет делать это самостоятельно внутри сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unlikely-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(\n",
       "  (layers): Sequential(\n",
       "    (layer1): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (layer2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dropout2): Dropout(p=0.0, inplace=False)\n",
       "    (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perceptron(num_layers=2, device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-wallet",
   "metadata": {},
   "source": [
    "В данном случае скрытых слоев уже два. Также учтена согласованность входов и выходов между смежными слоями:  \n",
    "Скрытый: `in_features=784, out_features=64`  \n",
    "Скрытый: `in_features=64, out_features=64`  \n",
    "Выходной: `in_features=64, out_features=10`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-iceland",
   "metadata": {},
   "source": [
    "Заметим, что все слои глубокой нейронной сети до выходного представляют собой Feature Engineering. Сам классификатор представляется последним слоем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hearing-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataset):\n",
    "    generator = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "    # batch_size=64 отвечает за количество объектов, читаемых в одном пакете\n",
    "    # То есть все объекты (в выборке порядка 60 000 объектов) будут браться\n",
    "    # поочередно пакетами по 64 объекта, чтобы не перегружать память.\n",
    "    \n",
    "    pred = []\n",
    "    real = []\n",
    "    for x,y in tqdm(generator, leave=False):\n",
    "        x = x.view([-1, 784]).to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        pred.extend(torch.argmax(model(x), dim=-1).cpu().numpy().tolist())\n",
    "        real.extend(y.cpu().numpy().tolist())\n",
    "        # если подсчет torch.argmax(model(x), dim=-1) производится на GPU,\n",
    "        # то и все промежуточные результаты будут храниться в видеопамяти.\n",
    "        # Для сохранения результатов в оперативную память, необходимо\n",
    "        # перегонять все на процессор применяя .cpu().\n",
    "        # .numpy().tolist() применяется просто для преобразования в удобный \n",
    "        # формат.\n",
    "        \n",
    "    return np.mean(np.array(real) == np.array(pred)), \\\n",
    "           classification_report(real, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-economy",
   "metadata": {},
   "source": [
    "В данном коде есть минус. Backward работает быстро за счет того, что он помнит все, что считал по дороге. На момент тестирования градиент нам не понадобится, но в данном случае Torch сохранит все промежуточные состояния. Это можно исправить, добавив специальную команду (будет далее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
